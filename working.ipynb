{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSabarish/Product-Recommenders--Amazon/blob/main/working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqIJYwwCIsdE"
      },
      "source": [
        "<h1><b><font color='blue'>Product Recommendation Model using Content-Based Filtering</font></b></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvOm3rrcIsdK"
      },
      "source": [
        "## <b>Introduction</b>\n",
        "\n",
        "This **IPython notebook** introduces a robust **Product Recommendation Model** aimed at optimizing user engagement on e-commerce platforms like **Amazon** and **Flipkart**. Recommendation systems typically utilize two main approaches:\n",
        "\n",
        "## <b>Methods of Recommendation</b>\n",
        "\n",
        ">### <b>Content-Based Filtering</b>\n",
        "In a **content-based recommendation system**, product recommendations are generated based on the **attributes** of the products themselves, such as **textual descriptions** or **image features**. This approach ensures that products similar in content to those searched or viewed by the user are suggested.\n",
        "\n",
        ">### <b>Collaborative Filtering</b>\n",
        "**Collaborative filtering**, another widely used method, relies on **user behavior data**. It suggests items based on the preferences and behavior patterns of similar users. However, due to data constraints in this project, I focus exclusively on **content-based recommendation**.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5WTl6s8N5Sz"
      },
      "source": [
        "### [4.3] Overview of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RW8Y5ILVN5S1",
        "outputId": "e99c46a6-2909-4665-fa19-9eaf37ff588c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import All Necessary Packages\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import math\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
        "from matplotlib import gridspec\n",
        "from scipy.sparse import hstack\n",
        "import plotly\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.graph_objs import Scatter, Layout\n",
        "\n",
        "plotly.offline.init_notebook_mode(connected=True)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gq1rL7vyN5TB",
        "outputId": "810870bb-f86c-404f-8f05-4b7d7fbb4e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1y3tPyepPOweL1oez05g1O_bAZZShiaoZ\n",
            "From (redirected): https://drive.google.com/uc?id=1y3tPyepPOweL1oez05g1O_bAZZShiaoZ&confirm=t&uuid=12f909b3-7b33-4dcf-a10b-f3a1295c456f\n",
            "To: /content/tops_fashion.json\n",
            "100%|██████████| 263M/263M [00:03<00:00, 82.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tops_fashion.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "# Google Drive URL\n",
        "url = \"https://drive.google.com/file/d/1y3tPyepPOweL1oez05g1O_bAZZShiaoZ/view?usp=drive_link\"\n",
        "\n",
        "# Extract the file ID from the URL\n",
        "file_id = url.split('/')[5]\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Download the file\n",
        "output = 'tops_fashion.json'\n",
        "gdown.download(download_url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rcq0FwETIsdX",
        "outputId": "792c8817-2cec-4264-e162-034d25e09bfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data Loaded Successfully'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data = pd.read_json(output)\n",
        "\"Data Loaded Successfully\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "InPpUbKrIsdZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBGmJv35N5TH",
        "outputId": "be798a71-4168-4b4f-bfa2-8bec445abc41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points: 183138\n",
            "Number of features/variables: 19\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of data points: {data.shape[0]}\")\n",
        "print(f\"Number of features/variables: {data.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYYfo41iN5TO"
      },
      "source": [
        "### **Terminology:**\n",
        "- **Dataset:** A collection of data points or observations.\n",
        "- **Rows and columns:** The rows represent individual data points, while columns represent variables or features describing each data point.\n",
        "- **Data-point:** A single instance or observation within a dataset.\n",
        "- **Feature/variable:** A measurable property or characteristic of a data-point, stored in columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uZ_UmJLN5TQ",
        "outputId": "f271cd11-114a-4450-a118-be36e8896b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features per product/item: 19\n",
            "Column names (feature names) and data types:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 183138 entries, 0 to 183137\n",
            "Data columns (total 19 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   sku                363 non-null     object\n",
            " 1   asin               183138 non-null  object\n",
            " 2   product_type_name  183138 non-null  object\n",
            " 3   formatted_price    28395 non-null   object\n",
            " 4   author             1 non-null       object\n",
            " 5   color              64956 non-null   object\n",
            " 6   brand              182987 non-null  object\n",
            " 7   publisher          42899 non-null   object\n",
            " 8   availability       24532 non-null   object\n",
            " 9   reviews            183138 non-null  object\n",
            " 10  large_image_url    183138 non-null  object\n",
            " 11  availability_type  24559 non-null   object\n",
            " 12  small_image_url    183138 non-null  object\n",
            " 13  editorial_review   2758 non-null    object\n",
            " 14  title              183138 non-null  object\n",
            " 15  model              62370 non-null   object\n",
            " 16  medium_image_url   183138 non-null  object\n",
            " 17  manufacturer       42899 non-null   object\n",
            " 18  editorial_reivew   180380 non-null  object\n",
            "dtypes: object(19)\n",
            "memory usage: 26.5+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Each product/item has 19 features in the raw dataset\n",
        "print(\"Number of features per product/item:\", data.shape[1])\n",
        "print(\"Column names (feature names) and data types:\")\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pKNNNSpN5TY"
      },
      "source": [
        "**Features:**\n",
        "\n",
        "Of these 19 features, we will be using only 6 features in this analysis and modeling:\n",
        "\n",
        "1. **asin**: Amazon Standard Identification Number\n",
        "2. **brand**: Brand to which the product belongs\n",
        "3. **color**: Color information of the apparel (can contain multiple colors)\n",
        "4. **product_type_name**: Type of the apparel (e.g., SHIRT, TSHIRT)\n",
        "5. **medium_image_url**: URL of the product image\n",
        "6. **title**: Title of the product\n",
        "7. **formatted_price**: Price of the product\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5dCtPbdQN5Ta",
        "outputId": "d060d056-981c-428b-b748-1d9e163f0185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         asin         brand              color  \\\n",
              "0  B016I2TS4W         FNC7C               None   \n",
              "1  B01N49AI08  FIG Clothing               None   \n",
              "2  B01JDPCOHO  FIG Clothing               None   \n",
              "3  B01N19U5H5       Focal18               None   \n",
              "4  B004GSI2OS   FeatherLite  Onyx Black/ Stone   \n",
              "\n",
              "                                    medium_image_url product_type_name  \\\n",
              "0  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "1  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "2  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "3  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "4  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "\n",
              "                                               title formatted_price  \n",
              "0  Minions Como Superheroes Ironman Long Sleeve R...            None  \n",
              "1                      FIG Clothing Womens Izo Tunic            None  \n",
              "2                        FIG Clothing Womens Won Top            None  \n",
              "3  Focal18 Sailor Collar Bubble Sleeve Blouse Shi...            None  \n",
              "4  Featherlite Ladies' Long Sleeve Stain Resistan...          $26.26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a5ffcbb-1dc3-4223-832a-93b97d08f050\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>brand</th>\n",
              "      <th>color</th>\n",
              "      <th>medium_image_url</th>\n",
              "      <th>product_type_name</th>\n",
              "      <th>title</th>\n",
              "      <th>formatted_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B016I2TS4W</td>\n",
              "      <td>FNC7C</td>\n",
              "      <td>None</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>Minions Como Superheroes Ironman Long Sleeve R...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B01N49AI08</td>\n",
              "      <td>FIG Clothing</td>\n",
              "      <td>None</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>FIG Clothing Womens Izo Tunic</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B01JDPCOHO</td>\n",
              "      <td>FIG Clothing</td>\n",
              "      <td>None</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>FIG Clothing Womens Won Top</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B01N19U5H5</td>\n",
              "      <td>Focal18</td>\n",
              "      <td>None</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>Focal18 Sailor Collar Bubble Sleeve Blouse Shi...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B004GSI2OS</td>\n",
              "      <td>FeatherLite</td>\n",
              "      <td>Onyx Black/ Stone</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>Featherlite Ladies' Long Sleeve Stain Resistan...</td>\n",
              "      <td>$26.26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a5ffcbb-1dc3-4223-832a-93b97d08f050')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a5ffcbb-1dc3-4223-832a-93b97d08f050 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a5ffcbb-1dc3-4223-832a-93b97d08f050');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec9b1878-aa51-4c7d-977a-6e964f4458f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec9b1878-aa51-4c7d-977a-6e964f4458f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec9b1878-aa51-4c7d-977a-6e964f4458f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# List of columns to extract\n",
        "columns_to_extract = ['asin', 'brand', 'color', 'medium_image_url',\n",
        "                      'product_type_name', 'title', 'formatted_price']\n",
        "\n",
        "# Extracting specified columns from the DataFrame\n",
        "data = data[columns_to_extract]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJusqAspN5Tg",
        "outputId": "c4265860-0f52-4e99-9530-f4e30522f074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points: 183138\n",
            "Number of features/variables: 7\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of data points: {data.shape[0]}\")\n",
        "print(f\"Number of features/variables: {data.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKkmHvgLN5To"
      },
      "source": [
        "### [5.1] Missing data for various features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4PD4YHJaIsdh"
      },
      "outputs": [],
      "source": [
        "def describe_feature(df, column_name):\n",
        "    \"\"\"\n",
        "    Describe the given feature with various statistics and details.\n",
        "\n",
        "    Parameters:\n",
        "    - df: Pandas DataFrame, the DataFrame containing the feature to analyze.\n",
        "    - column_name: str, the name of the column (feature) to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - None (outputs results directly).\n",
        "    \"\"\"\n",
        "    # Extract the feature (column) from the DataFrame\n",
        "    feature = df[column_name]\n",
        "\n",
        "    # Calculate top group statistics\n",
        "    top_group = feature.mode().iloc[0]\n",
        "    top_group_count = feature.value_counts().max()\n",
        "    total_count = df.shape[0]\n",
        "    top_group_percentage = (top_group_count / total_count) * 100\n",
        "\n",
        "    # Display top 10 values and their counts\n",
        "    print(\"\\nTop 10 values and their counts:\")\n",
        "    print(feature.value_counts().head(10))\n",
        "\n",
        "    # Display percentage of items from top group\n",
        "    print(f\"\\n◼ {top_group_percentage:.2f}% of items are from the '{top_group}' group.\")\n",
        "\n",
        "    # Display number of unique values\n",
        "    unique_values_count = feature.nunique()\n",
        "    print(f\"◼ Number of unique values: {unique_values_count}\")\n",
        "\n",
        "    # Display number of null values\n",
        "    null_values_count = feature.isnull().sum()\n",
        "    null_percentage = (null_values_count / df.shape[0]) * 100\n",
        "    print(f\"◼ Number of null values: {null_values_count} ({null_percentage:.2f}% of total)\")\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'data' is your DataFrame and 'brand' is the column of interest\n",
        "# describe_feature(data, 'brand')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8NbRPUYN5Tq"
      },
      "source": [
        "####  Basic stats for the feature: product_type_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtQatzvpghzj",
        "outputId": "9d44d64d-f32c-4925-a78f-39c7c87f8869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 values and their counts:\n",
            "product_type_name\n",
            "SHIRT                         167794\n",
            "APPAREL                         3549\n",
            "BOOKS_1973_AND_LATER            3336\n",
            "DRESS                           1584\n",
            "SPORTING_GOODS                  1281\n",
            "SWEATER                          837\n",
            "OUTERWEAR                        796\n",
            "OUTDOOR_RECREATION_PRODUCT       729\n",
            "ACCESSORY                        636\n",
            "UNDERWEAR                        425\n",
            "Name: count, dtype: int64\n",
            "\n",
            "◼ 91.62% of items are from the 'SHIRT' group.\n",
            "◼ Number of unique values: 72\n",
            "◼ Number of null values: 0 (0.00% of total)\n"
          ]
        }
      ],
      "source": [
        "describe_feature(data, 'product_type_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QWwGm9cN5Tz",
        "outputId": "99a1b546-b132-4706-e706-e90dbc7d9f0c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['SHIRT', 'SWEATER', 'APPAREL', 'OUTDOOR_RECREATION_PRODUCT',\n",
              "       'BOOKS_1973_AND_LATER', 'PANTS', 'HAT', 'SPORTING_GOODS', 'DRESS',\n",
              "       'UNDERWEAR', 'SKIRT', 'OUTERWEAR', 'BRA', 'ACCESSORY',\n",
              "       'ART_SUPPLIES', 'SLEEPWEAR', 'ORCA_SHIRT', 'HANDBAG',\n",
              "       'PET_SUPPLIES', 'SHOES', 'KITCHEN', 'ADULT_COSTUME',\n",
              "       'HOME_BED_AND_BATH', 'MISC_OTHER', 'BLAZER',\n",
              "       'HEALTH_PERSONAL_CARE', 'TOYS_AND_GAMES', 'SWIMWEAR',\n",
              "       'CONSUMER_ELECTRONICS', 'SHORTS', 'HOME', 'AUTO_PART',\n",
              "       'OFFICE_PRODUCTS', 'ETHNIC_WEAR', 'BEAUTY',\n",
              "       'INSTRUMENT_PARTS_AND_ACCESSORIES', 'POWERSPORTS_PROTECTIVE_GEAR',\n",
              "       'SHIRTS', 'ABIS_APPAREL', 'AUTO_ACCESSORY', 'NONAPPARELMISC',\n",
              "       'TOOLS', 'BABY_PRODUCT', 'SOCKSHOSIERY',\n",
              "       'POWERSPORTS_RIDING_SHIRT', 'EYEWEAR', 'SUIT', 'OUTDOOR_LIVING',\n",
              "       'POWERSPORTS_RIDING_JACKET', 'HARDWARE', 'SAFETY_SUPPLY',\n",
              "       'ABIS_DVD', 'VIDEO_DVD', 'GOLF_CLUB', 'MUSIC_POPULAR_VINYL',\n",
              "       'HOME_FURNITURE_AND_DECOR', 'TABLET_COMPUTER', 'GUILD_ACCESSORIES',\n",
              "       'ABIS_SPORTS', 'ART_AND_CRAFT_SUPPLY', 'BAG',\n",
              "       'MECHANICAL_COMPONENTS', 'SOUND_AND_RECORDING_EQUIPMENT',\n",
              "       'COMPUTER_COMPONENT', 'JEWELRY', 'BUILDING_MATERIAL', 'LUGGAGE',\n",
              "       'BABY_COSTUME', 'POWERSPORTS_VEHICLE_PART',\n",
              "       'PROFESSIONAL_HEALTHCARE', 'SEEDS_AND_PLANTS',\n",
              "       'WIRELESS_ACCESSORY'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Names of different product types\n",
        "data['product_type_name'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QybvKw9vN5UC"
      },
      "source": [
        "####  Basic stats for the feature: brand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uSZnupON5UE",
        "outputId": "c0ccc10e-406f-466c-8b6f-911432c2f20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 values and their counts:\n",
            "brand\n",
            "Zago                         223\n",
            "XQS                          222\n",
            "Yayun                        215\n",
            "YUNY                         198\n",
            "XiaoTianXin-women clothes    193\n",
            "Generic                      192\n",
            "Boohoo                       190\n",
            "Alion                        188\n",
            "TheMogan                     187\n",
            "Abetteric                    187\n",
            "Name: count, dtype: int64\n",
            "\n",
            "◼ 0.12% of items are from the 'Zago' group.\n",
            "◼ Number of unique values: 10577\n",
            "◼ Number of null values: 151 (0.08% of total)\n"
          ]
        }
      ],
      "source": [
        "describe_feature(data, 'brand')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ9aFHW9N5US"
      },
      "source": [
        "####  Basic stats for the feature: color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D7i98-lDN5UW",
        "outputId": "3ad8ad2a-7a7c-455f-9edc-2462ffd078e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 values and their counts:\n",
            "color\n",
            "Black    13207\n",
            "White     8616\n",
            "Blue      3570\n",
            "Red       2289\n",
            "Pink      1842\n",
            "Grey      1499\n",
            "*         1388\n",
            "Green     1258\n",
            "Multi     1203\n",
            "Gray      1189\n",
            "Name: count, dtype: int64\n",
            "\n",
            "◼ 7.21% of items are from the 'Black' group.\n",
            "◼ Number of unique values: 7380\n",
            "◼ Number of null values: 118182 (64.53% of total)\n"
          ]
        }
      ],
      "source": [
        "describe_feature(data, 'color')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNvmp1eeN5Un"
      },
      "source": [
        "####  Basic stats for the feature: formatted_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iFWC6ZnoN5Uo",
        "outputId": "7f20da40-d80a-4ddf-da06-a2849874dc39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 values and their counts:\n",
            "formatted_price\n",
            "$19.99    945\n",
            "$9.99     749\n",
            "$9.50     601\n",
            "$14.99    472\n",
            "$7.50     463\n",
            "$24.99    414\n",
            "$29.99    370\n",
            "$8.99     343\n",
            "$9.01     336\n",
            "$16.99    317\n",
            "Name: count, dtype: int64\n",
            "\n",
            "◼ 0.52% of items are from the '$19.99' group.\n",
            "◼ Number of unique values: 3135\n",
            "◼ Number of null values: 154743 (84.50% of total)\n"
          ]
        }
      ],
      "source": [
        "describe_feature(data, 'formatted_price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYHl4cPhN5U4"
      },
      "source": [
        "#### Basic stats for the feature: title\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UjR_SBO7N5U5",
        "outputId": "eaa96b39-45d9-4383-8502-726baebdb87a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 values and their counts:\n",
            "title\n",
            "Nakoda Cotton Self Print Straight Kurti For Women                                77\n",
            "Q-rious Women's Racerback Cotton Lycra Camsioles                                 56\n",
            "FINEJO Casual Women Long Sleeve Lace Irregular Hem Blouse Tops                   47\n",
            "Girlzwalk Women Cami Sleeveless Printed Swing Vest Top Plus Sizes                44\n",
            "ELINA FASHION Women's Indo-Western Tunic Top Cotton Kurti                        43\n",
            "Victoria Scoop Neck Front Lace Floral High-Low Top in 4 Sizes                    40\n",
            "Cenizas Women's Indian Tunic Top Cotton Kurti                                    39\n",
            "Indistar Womens Premium Cotton Half Sleeves Printed T-Shirts/Tops (Pack of 3)    37\n",
            "Rajnandini Women's Cotton Printed Kurti                                          35\n",
            "Long Sleeve Mock Neck Top                                                        32\n",
            "Name: count, dtype: int64\n",
            "\n",
            "◼ 0.04% of items are from the 'Nakoda Cotton Self Print Straight Kurti For Women' group.\n",
            "◼ Number of unique values: 175985\n",
            "◼ Number of null values: 0 (0.00% of total)\n"
          ]
        }
      ],
      "source": [
        "# All products have a title.\n",
        "# Titles are typically descriptive of the product.\n",
        "# Titles are used extensively because they are concise and informative.\n",
        "\n",
        "describe_feature(data, 'title')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WZmkSpr6Isdo"
      },
      "outputs": [],
      "source": [
        "# Create a directory for pickle files if it doesn't exist\n",
        "pickle_folder = 'pickles'\n",
        "os.makedirs(pickle_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "acwxdouEN5VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a93628-4f4a-4e61-e7a1-3ac4f3f3d167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as '180k_apparel_data.pkl' in 'pickles' folder.\n"
          ]
        }
      ],
      "source": [
        "# Save DataFrame to pickle file\n",
        "data.to_pickle(os.path.join(pickle_folder, '180k_apparel_data.pkl'))\n",
        "print(f\"DataFrame saved as '180k_apparel_data.pkl' in '{pickle_folder}' folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uxNyGaE_N5VH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1275099-774e-4fef-c675-494d73f7d85d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pickle Loaded'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# We save data files at every major step in our processing as \"pickle\" files.\n",
        "# If you are stuck or if some code takes too long to run on your laptop,\n",
        "# you may use the pickle files we provide to speed things up.\n",
        "\n",
        "# Load DataFrame from pickle file\n",
        "data = pd.read_pickle('pickles/180k_apparel_data.pkl')\n",
        "\"pickle Loaded\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lw4b9U7CIsdq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rFSTXhh-N5VJ",
        "outputId": "4fcdbeba-9b8f-4bc9-a0f1-5ffa2ee86b63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points after removing price=NULL: 28395\n"
          ]
        }
      ],
      "source": [
        "# Include only products with available price information.\n",
        "# data['formatted_price'].isnull() identifies rows where price is None or Null.\n",
        "# Exclude rows where price is Null.\n",
        "\n",
        "data = data[data['formatted_price'].notnull()]\n",
        "print('Number of data points after removing price=NULL:', data.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CT4sVFQGN5VP",
        "outputId": "b9dcf57e-116a-4d19-f467-158551de89fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points after filtering out color=NULL: 28385\n"
          ]
        }
      ],
      "source": [
        "# Consider products with color information.\n",
        "# Filter out rows where color is Null using data['color'].notnull().\n",
        "\n",
        "data = data[data['color'].notnull()]\n",
        "print('Number of data points after filtering out color=NULL:', data.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg9rkk2QN5VV"
      },
      "source": [
        "✅ We've reduced the dataset from 183K to 28K points. <br>\n",
        "✅ This change ensures most workshop participants can run the code on their laptops in a reasonable time.<br>\n",
        "✅ For those with powerful computers and more time, using all 183K images is recommended.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TSAvpncIN5VX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572be61c-4385-43e6-89c6-c5bfb0b30a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as '28k_apparel_data.pkl' in 'pickles' folder.\n"
          ]
        }
      ],
      "source": [
        "# Save DataFrame to pickle file\n",
        "data.to_pickle(os.path.join(pickle_folder, '28k_apparel_data.pkl'))\n",
        "print(f\"DataFrame saved as '28k_apparel_data.pkl' in '{pickle_folder}' folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZCClrtiTIsdu",
        "outputId": "ab5c3212-cc80-4cc0-c51f-e009a837cfd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pickle Loaded'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Load DataFrame from pickle file\n",
        "data = pd.read_pickle('pickles/28k_apparel_data.pkl')\n",
        "\"pickle Loaded\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceBZ9pvxIsdw",
        "outputId": "10ec3088-4c02-4924-f79c-18dcb66ec2dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['asin', 'brand', 'color', 'medium_image_url', 'product_type_name',\n",
              "       'title', 'formatted_price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i_POLXz-N5Vd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# '''\n",
        "# from PIL import Image\n",
        "# import requests\n",
        "# from io import BytesIO\n",
        "\n",
        "# for index, row in images.iterrows():\n",
        "#         url = row['medium_image_url']\n",
        "#         response = requests.get(url)\n",
        "#         img = Image.open(BytesIO(response.content))\n",
        "#         img.save('images/28k_images/'+row['asin']+'.jpeg')\n",
        "\n",
        "\n",
        "# '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOzAxFh8N5Vj"
      },
      "source": [
        "### [5.2] Remove near duplicate items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnzGS8hpN5Vl"
      },
      "source": [
        "#### [5.2.1] Understand about duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-hO9lbDLN5Vr",
        "outputId": "74dae701-001d-4e88-c0a4-942dfdc87d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of products with duplicate titles: 2325\n",
            "We have 2325 products that have the same title but different colors.\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_pickle('pickles/28k_apparel_data.pkl')                                              # Read data from the pickle file from the previous stage\n",
        "\n",
        "duplicate_titles_count = sum(data.duplicated('title'))                                             # Find the number of products that have duplicate titles\n",
        "print(f\"Number of products with duplicate titles: {duplicate_titles_count}\")\n",
        "\n",
        "print(f\"We have {duplicate_titles_count} products that have the same title but different colors.\") # Output a specific note about the duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_9U6qzN5Vw"
      },
      "source": [
        "#### These shirts are exactly same, except in size (S, M,L,XL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qgLgJaGIsd1"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<td><img src=\"dedupe/B00AQ4GMCK.jpeg\" width=\"100\" height=\"100\"> :B00AQ4GMCK</td>\n",
        "<td><img src=\"dedupe/B00AQ4GMTS.jpeg\" width=\"100\" height=\"100\"> :B00AQ4GMTS</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><img src=\"dedupe/B00AQ4GMLQ.jpeg\" width=\"100\" height=\"100\"> :B00AQ4GMLQ</td>\n",
        "<td><img src=\"dedupe/B00AQ4GN3I.jpeg\" width=\"100\" height=\"100\"> :B00AQ4GN3I</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpoIc6DxN5V1"
      },
      "source": [
        "#### These shirts exactly same except  in color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kulQdKRQN5V2"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<td><img src=\"dedupe/B00G278GZ6.jpeg\" width=\"100\" height=\"100\"> : B00G278GZ6</td>\n",
        "<td><img src=\"dedupe/B00G278W6O.jpeg\" width=\"100\" height=\"100\"> : B00G278W6O</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><img src=\"dedupe/B00G278Z2A.jpeg\" width=\"100\" height=\"100\"> : B00G278Z2A</td>\n",
        "<td><img src=\"dedupe/B00G2786X8.jpeg\" width=\"100\" height=\"100\"> : B00G2786X8</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y8G7oJyN5V4"
      },
      "source": [
        "#### In our data there are many duplicate products like the above examples, we need to de-dupe them for better results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMAXj4i2N5V6"
      },
      "source": [
        "#### [5.2.2] Remove duplicates : Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vBYh8PriN5V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc5369f-6ac0-4e7f-beeb-0b1b9b08039a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 28385 entries, 4 to 183136\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   asin               28385 non-null  object\n",
            " 1   brand              28292 non-null  object\n",
            " 2   color              28385 non-null  object\n",
            " 3   medium_image_url   28385 non-null  object\n",
            " 4   product_type_name  28385 non-null  object\n",
            " 5   title              28385 non-null  object\n",
            " 6   formatted_price    28385 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ],
      "source": [
        "# Read data from the pickle file from the previous stage\n",
        "data = pd.read_pickle('pickles/28k_apparel_data.pkl')\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OwqqkUJgN5WF",
        "outputId": "9e891688-c01d-4a9c-fa8b-e94640aeb2cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removal of products with short description: 27949\n"
          ]
        }
      ],
      "source": [
        "# Remove All products with very few words in title\n",
        "data_sorted = data[data['title'].apply(lambda x: len(x.split())>4)]\n",
        "print(\"After removal of products with short description:\", data_sorted.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "w3CZgh80N5WK",
        "outputId": "d4805371-1917-427c-8fe8-02517cc3afdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              asin     brand        color  \\\n",
              "61973   B06Y1KZ2WB    Éclair   Black/Pink   \n",
              "133820  B010RV33VE  xiaoming         Pink   \n",
              "81461   B01DDSDLNS  xiaoming        White   \n",
              "75995   B00X5LYO9Y  xiaoming  Red Anchors   \n",
              "151570  B00WPJG35K  xiaoming        White   \n",
              "\n",
              "                                         medium_image_url product_type_name  \\\n",
              "61973   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "133820  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "81461   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "75995   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "151570  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
              "\n",
              "                                                    title formatted_price  \n",
              "61973   Éclair Women's Printed Thin Strap Blouse Black...          $24.99  \n",
              "133820  xiaoming Womens Sleeveless Loose Long T-shirts...          $18.19  \n",
              "81461   xiaoming Women's White Long Sleeve Single Brea...          $21.58  \n",
              "75995   xiaoming Stripes Tank Patch/Bear Sleeve Anchor...          $15.91  \n",
              "151570  xiaoming Sleeve Sheer Loose Tassel Kimono Woma...          $14.32  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56b63856-ee35-40e3-80e6-52f84e587849\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asin</th>\n",
              "      <th>brand</th>\n",
              "      <th>color</th>\n",
              "      <th>medium_image_url</th>\n",
              "      <th>product_type_name</th>\n",
              "      <th>title</th>\n",
              "      <th>formatted_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61973</th>\n",
              "      <td>B06Y1KZ2WB</td>\n",
              "      <td>Éclair</td>\n",
              "      <td>Black/Pink</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>Éclair Women's Printed Thin Strap Blouse Black...</td>\n",
              "      <td>$24.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133820</th>\n",
              "      <td>B010RV33VE</td>\n",
              "      <td>xiaoming</td>\n",
              "      <td>Pink</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>xiaoming Womens Sleeveless Loose Long T-shirts...</td>\n",
              "      <td>$18.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81461</th>\n",
              "      <td>B01DDSDLNS</td>\n",
              "      <td>xiaoming</td>\n",
              "      <td>White</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>xiaoming Women's White Long Sleeve Single Brea...</td>\n",
              "      <td>$21.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75995</th>\n",
              "      <td>B00X5LYO9Y</td>\n",
              "      <td>xiaoming</td>\n",
              "      <td>Red Anchors</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>xiaoming Stripes Tank Patch/Bear Sleeve Anchor...</td>\n",
              "      <td>$15.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151570</th>\n",
              "      <td>B00WPJG35K</td>\n",
              "      <td>xiaoming</td>\n",
              "      <td>White</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>SHIRT</td>\n",
              "      <td>xiaoming Sleeve Sheer Loose Tassel Kimono Woma...</td>\n",
              "      <td>$14.32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56b63856-ee35-40e3-80e6-52f84e587849')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56b63856-ee35-40e3-80e6-52f84e587849 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56b63856-ee35-40e3-80e6-52f84e587849');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac2b6bfa-8e9a-4530-be7c-812dddb79c05\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac2b6bfa-8e9a-4530-be7c-812dddb79c05')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac2b6bfa-8e9a-4530-be7c-812dddb79c05 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data_sorted[:5]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"B010RV33VE\",\n          \"B00WPJG35K\",\n          \"B01DDSDLNS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"xiaoming\",\n          \"\\u00c9clair\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"color\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Pink\",\n          \"Red Anchors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"medium_image_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://images-na.ssl-images-amazon.com/images/I/41m2REUXzxL._SL160_.jpg\",\n          \"https://images-na.ssl-images-amazon.com/images/I/41qKCBHqWIL._SL160_.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_type_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SHIRT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"xiaoming Womens Sleeveless Loose Long T-shirts Top Blouse Shirts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"formatted_price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"$18.19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Sort the whole data based on title (alphabetical order of title)\n",
        "data_sorted.sort_values('title',inplace=True, ascending=False)\n",
        "data_sorted[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNci6ckEN5WQ"
      },
      "source": [
        "#### Some examples of dupliacte titles that differ only in the last few words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WzpmDx2N5WR"
      },
      "source": [
        "<pre>\n",
        "Titles 1:\n",
        "16. woman's place is in the house and the senate shirts for Womens XXL White\n",
        "17. woman's place is in the house and the senate shirts for Womens M Grey\n",
        "\n",
        "Title 2:\n",
        "25. tokidoki The Queen of Diamonds Women's Shirt X-Large\n",
        "26. tokidoki The Queen of Diamonds Women's Shirt Small\n",
        "27. tokidoki The Queen of Diamonds Women's Shirt Large\n",
        "\n",
        "Title 3:\n",
        "61. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
        "62. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
        "63. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
        "64. psychedelic colorful Howling Galaxy Wolf T-shirt/Colorful Rainbow Animal Print Head Shirt for woman Neon Wolf t-shirt\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1Ok8p2lgN5WT"
      },
      "outputs": [],
      "source": [
        "indices = []\n",
        "for i,row in data_sorted.iterrows():\n",
        "    indices.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "si_nZNoTN5WY"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "stage1_dedupe_asins = []\n",
        "i = 0\n",
        "j = 0\n",
        "num_data_points = data_sorted.shape[0]\n",
        "while i < num_data_points and j < num_data_points:\n",
        "\n",
        "    previous_i = i\n",
        "\n",
        "    # store the list of words of ith string in a, ex: a = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
        "    a = data['title'].loc[indices[i]].split()\n",
        "\n",
        "    # search for the similar products sequentially\n",
        "    j = i+1\n",
        "    while j < num_data_points:\n",
        "\n",
        "        # store the list of words of jth string in b, ex: b = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'Small']\n",
        "        b = data['title'].loc[indices[j]].split()\n",
        "\n",
        "        # store the maximum length of two strings\n",
        "        length = max(len(a), len(b))\n",
        "\n",
        "        # count is used to store the number of words that are matched in both strings\n",
        "        count  = 0\n",
        "\n",
        "        # itertools.zip_longest(a,b): will map the corresponding words in both strings, it will appened None in case of unequal strings\n",
        "        # example: a =['a', 'b', 'c', 'd']\n",
        "        # b = ['a', 'b', 'd']\n",
        "        # itertools.zip_longest(a,b): will give [('a','a'), ('b','b'), ('c','d'), ('d', None)]\n",
        "        for k in itertools.zip_longest(a,b):\n",
        "            if (k[0] == k[1]):\n",
        "                count += 1\n",
        "\n",
        "        # if the number of words in which both strings differ are > 2 , we are considering it as those two apperals are different\n",
        "        # if the number of words in which both strings differ are < 2 , we are considering it as those two apperals are same, hence we are ignoring them\n",
        "        if (length - count) > 2: # number of words in which both sensences differ\n",
        "            # if both strings are differ by more than 2 words we include the 1st string index\n",
        "            stage1_dedupe_asins.append(data_sorted['asin'].loc[indices[i]])\n",
        "\n",
        "            # if the comaprision between is between num_data_points, num_data_points-1 strings and they differ in more than 2 words we include both\n",
        "            if j == num_data_points-1: stage1_dedupe_asins.append(data_sorted['asin'].loc[indices[j]])\n",
        "\n",
        "            # start searching for similar apperals corresponds 2nd string\n",
        "            i = j\n",
        "            break\n",
        "        else:\n",
        "            j += 1\n",
        "    if previous_i == i:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MAfgf_CNN5Wg"
      },
      "outputs": [],
      "source": [
        "data = data.loc[data['asin'].isin(stage1_dedupe_asins)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2ufVooHN5Wl"
      },
      "source": [
        "#### We removed  the dupliactes which differ only at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9ctWdfBWN5Wn",
        "outputId": "a0a01078-a60f-48a2-8040-605c04c82566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points :  17593\n"
          ]
        }
      ],
      "source": [
        "print('Number of data points : ', data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Hgm2pYUuN5Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0259d357-d98e-4676-834b-06de345788fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as '17k_apparel_data.pkl' in 'pickles' folder.\n"
          ]
        }
      ],
      "source": [
        "# Save DataFrame to pickle file\n",
        "pickle_folder = 'pickles'  # Ensure this directory exists\n",
        "data.to_pickle(os.path.join(pickle_folder, '17k_apparel_data.pkl'))\n",
        "print(f\"DataFrame saved as '17k_apparel_data.pkl' in '{pickle_folder}' folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSKThlqLN5W0"
      },
      "source": [
        "#### [5.2.3] Remove duplicates : Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqHGzrunN5W1"
      },
      "source": [
        "<pre>\n",
        "\n",
        "In the previous cell, we sorted whole data in alphabetical order of  titles.Then, we removed titles which are adjacent and very similar title\n",
        "\n",
        "But there are some products whose titles are not adjacent but very similar.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Titles-1\n",
        "86261.  UltraClub Women's Classic Wrinkle-Free Long Sleeve Oxford Shirt, Pink, XX-Large\n",
        "115042. UltraClub Ladies Classic Wrinkle-Free Long-Sleeve Oxford Light Blue XXL\n",
        "\n",
        "TItles-2\n",
        "75004.  EVALY Women's Cool University Of UTAH 3/4 Sleeve Raglan Tee\n",
        "109225. EVALY Women's Unique University Of UTAH 3/4 Sleeve Raglan Tees\n",
        "120832. EVALY Women's New University Of UTAH 3/4-Sleeve Raglan Tshirt\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KtUSivYdN5W3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1188cbac-89e4-4585-bec4-276cf3dc72ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 17593 entries, 4 to 183120\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   asin               17593 non-null  object\n",
            " 1   brand              17543 non-null  object\n",
            " 2   color              17593 non-null  object\n",
            " 3   medium_image_url   17593 non-null  object\n",
            " 4   product_type_name  17593 non-null  object\n",
            " 5   title              17593 non-null  object\n",
            " 6   formatted_price    17593 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# Read data from the pickle file from the previous stage\n",
        "data = pd.read_pickle('pickles/17k_apparel_data.pkl')\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KggimVeJIzq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "nb1qQgIMN5W9",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# This code snippet takes significant amount of time.\n",
        "# O(n^2) time.\n",
        "# Takes about an hour to run on a decent computer.\n",
        "\n",
        "indices = []\n",
        "for i,row in data.iterrows():\n",
        "    indices.append(i)\n",
        "\n",
        "stage2_dedupe_asins = []\n",
        "while len(indices)!=0:\n",
        "    i = indices.pop()\n",
        "    stage2_dedupe_asins.append(data['asin'].loc[i])\n",
        "    # consider the first apperal's title\n",
        "    a = data['title'].loc[i].split()\n",
        "    # store the list of words of ith string in a, ex: a = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
        "    for j in indices:\n",
        "\n",
        "        b = data['title'].loc[j].split()\n",
        "        # store the list of words of jth string in b, ex: b = ['tokidoki', 'The', 'Queen', 'of', 'Diamonds', 'Women's', 'Shirt', 'X-Large']\n",
        "\n",
        "        length = max(len(a),len(b))\n",
        "\n",
        "        # count is used to store the number of words that are matched in both strings\n",
        "        count  = 0\n",
        "\n",
        "        # itertools.zip_longest(a,b): will map the corresponding words in both strings, it will appened None in case of unequal strings\n",
        "        # example: a =['a', 'b', 'c', 'd']\n",
        "        # b = ['a', 'b', 'd']\n",
        "        # itertools.zip_longest(a,b): will give [('a','a'), ('b','b'), ('c','d'), ('d', None)]\n",
        "        for k in itertools.zip_longest(a,b):\n",
        "            if (k[0]==k[1]):\n",
        "                count += 1\n",
        "\n",
        "        # if the number of words in which both strings differ are < 3 , we are considering it as those two apperals are same, hence we are ignoring them\n",
        "        if (length - count) < 3:\n",
        "            indices.remove(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": true,
        "id": "TFcWqm8UN5XB",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# from whole previous products we will consider only\n",
        "# the products that are found in previous cell\n",
        "data = data.loc[data['asin'].isin(stage2_dedupe_asins)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PB1QHpXAN5XE",
        "outputId": "f56995fd-2ccd-4440-d554-8b96d0d47d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points after stage two of dedupe:  16435\n"
          ]
        }
      ],
      "source": [
        "print('Number of data points after stage two of dedupe: ',data.shape[0])\n",
        "# from 17k apperals we reduced to 16k apperals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "id": "ImuDyQs5N5XO",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0403d2b5-502f-4a3f-e9e2-f2f070cb1267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as '16k_apperal_data.pkl' in 'pickles' folder.\n"
          ]
        }
      ],
      "source": [
        "# data.to_pickle('pickels/16k_apperal_data')\n",
        "# Storing these products in a pickle file\n",
        "# candidates who wants to download these files instead\n",
        "# of 180K they can download and use them from the Google Drive folder.\n",
        "# Save DataFrame to pickle file\n",
        "pickle_folder = 'pickles'  # Ensure this directory exists\n",
        "data.to_pickle(os.path.join(pickle_folder, '16k_apperal_data.pkl'))\n",
        "print(f\"DataFrame saved as '16k_apperal_data.pkl' in '{pickle_folder}' folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtvnBLTYN5XS"
      },
      "source": [
        "# 6. Text pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "T6oCATyfN5XT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d0da72d5-ecc1-44b4-b565-28af3210a8cd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'pickels/16k_apperal_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-0c991ba118e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pickels/16k_apperal_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# NLTK download stop words. [RUN ONLY ONCE]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# goto Terminal (Linux/Mac) or Command-Prompt (Window)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# In the temrinal, type these commands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pickels/16k_apperal_data'"
          ]
        }
      ],
      "source": [
        "data = pd.read_pickle('pickels/16k_apperal_data')\n",
        "\n",
        "# NLTK download stop words. [RUN ONLY ONCE]\n",
        "# goto Terminal (Linux/Mac) or Command-Prompt (Window)\n",
        "# In the temrinal, type these commands\n",
        "# $python3\n",
        "# $import nltk\n",
        "# $nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfVaQnE1N5XW"
      },
      "outputs": [],
      "source": [
        "# we use the list of stop words that are downloaded from nltk lib.\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print ('list of stop words:', stop_words)\n",
        "\n",
        "def nlp_preprocessing(total_text, index, column):\n",
        "    if type(total_text) is not int:\n",
        "        string = \"\"\n",
        "        for words in total_text.split():\n",
        "            # remove the special chars in review like '\"#$@!%^&*()_+-~?>< etc.\n",
        "            word = (\"\".join(e for e in words if e.isalnum()))\n",
        "            # Conver all letters to lower-case\n",
        "            word = word.lower()\n",
        "            # stop-word removal\n",
        "            if not word in stop_words:\n",
        "                string += word + \" \"\n",
        "        data[column][index] = string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZx2azSaN5Xb"
      },
      "outputs": [],
      "source": [
        "start_time = time.clock()\n",
        "# we take each title and we text-preprocess it.\n",
        "for index, row in data.iterrows():\n",
        "    nlp_preprocessing(row['title'], index, 'title')\n",
        "# we print the time it took to preprocess whole titles\n",
        "print(time.clock() - start_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqKJFtlPN5Xg"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRuf7IDSN5Xn"
      },
      "outputs": [],
      "source": [
        "data.to_pickle('pickels/16k_apperal_data_preprocessed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JypXMqKlN5Xq"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vfDV0k2N5Xr"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem('arguing'))\n",
        "print(stemmer.stem('fishing'))\n",
        "\n",
        "\n",
        "# We tried using stemming on our titles and it didnot work very well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smDFXz1TN5Xv"
      },
      "source": [
        "# [8] Text based product similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16IykU0bN5Xw"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle('pickels/16k_apperal_data_preprocessed')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8fSKXNKN5X1"
      },
      "outputs": [],
      "source": [
        "# Utility Functions which we will use through the rest of the workshop.\n",
        "\n",
        "\n",
        "#Display an image\n",
        "def display_img(url,ax,fig):\n",
        "    # we get the url of the apparel and download it\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    # we will display it in notebook\n",
        "    plt.imshow(img)\n",
        "\n",
        "#plotting code to understand the algorithm's decision.\n",
        "def plot_heatmap(keys, values, labels, url, text):\n",
        "        # keys: list of words of recommended title\n",
        "        # values: len(values) ==  len(keys), values(i) represents the occurence of the word keys(i)\n",
        "        # labels: len(labels) == len(keys), the values of labels depends on the model we are using\n",
        "                # if model == 'bag of words': labels(i) = values(i)\n",
        "                # if model == 'tfidf weighted bag of words':labels(i) = tfidf(keys(i))\n",
        "                # if model == 'idf weighted bag of words':labels(i) = idf(keys(i))\n",
        "        # url : apparel's url\n",
        "\n",
        "        # we will devide the whole figure into two parts\n",
        "        gs = gridspec.GridSpec(2, 2, width_ratios=[4,1], height_ratios=[4,1])\n",
        "        fig = plt.figure(figsize=(25,3))\n",
        "\n",
        "        # 1st, ploting heat map that represents the count of commonly ocurred words in title2\n",
        "        ax = plt.subplot(gs[0])\n",
        "        # it displays a cell in white color if the word is intersection(lis of words of title1 and list of words of title2), in black if not\n",
        "        ax = sns.heatmap(np.array([values]), annot=np.array([labels]))\n",
        "        ax.set_xticklabels(keys) # set that axis labels as the words of title\n",
        "        ax.set_title(text) # apparel title\n",
        "\n",
        "        # 2nd, plotting image of the the apparel\n",
        "        ax = plt.subplot(gs[1])\n",
        "        # we don't want any grid lines for image and no labels on x-axis and y-axis\n",
        "        ax.grid(False)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "        # we call dispaly_img based with paramete url\n",
        "        display_img(url, ax, fig)\n",
        "\n",
        "        # displays combine figure ( heat map and image together)\n",
        "        plt.show()\n",
        "\n",
        "def plot_heatmap_image(doc_id, vec1, vec2, url, text, model):\n",
        "\n",
        "    # doc_id : index of the title1\n",
        "    # vec1 : input apparels's vector, it is of a dict type {word:count}\n",
        "    # vec2 : recommended apparels's vector, it is of a dict type {word:count}\n",
        "    # url : apparels image url\n",
        "    # text: title of recomonded apparel (used to keep title of image)\n",
        "    # model, it can be any of the models,\n",
        "        # 1. bag_of_words\n",
        "        # 2. tfidf\n",
        "        # 3. idf\n",
        "\n",
        "    # we find the common words in both titles, because these only words contribute to the distance between two title vec's\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "\n",
        "    # we set the values of non intersecting words to zero, this is just to show the difference in heatmap\n",
        "    for i in vec2:\n",
        "        if i not in intersection:\n",
        "            vec2[i]=0\n",
        "\n",
        "    # for labeling heatmap, keys contains list of all words in title2\n",
        "    keys = list(vec2.keys())\n",
        "    #  if ith word in intersection(lis of words of title1 and list of words of title2): values(i)=count of that word in title2 else values(i)=0\n",
        "    values = [vec2[x] for x in vec2.keys()]\n",
        "\n",
        "    # labels: len(labels) == len(keys), the values of labels depends on the model we are using\n",
        "        # if model == 'bag of words': labels(i) = values(i)\n",
        "        # if model == 'tfidf weighted bag of words':labels(i) = tfidf(keys(i))\n",
        "        # if model == 'idf weighted bag of words':labels(i) = idf(keys(i))\n",
        "\n",
        "    if model == 'bag_of_words':\n",
        "        labels = values\n",
        "    elif model == 'tfidf':\n",
        "        labels = []\n",
        "        for x in vec2.keys():\n",
        "            # tfidf_title_vectorizer.vocabulary_ it contains all the words in the corpus\n",
        "            # tfidf_title_features[doc_id, index_of_word_in_corpus] will give the tfidf value of word in given document (doc_id)\n",
        "            if x in  tfidf_title_vectorizer.vocabulary_:\n",
        "                labels.append(tfidf_title_features[doc_id, tfidf_title_vectorizer.vocabulary_[x]])\n",
        "            else:\n",
        "                labels.append(0)\n",
        "    elif model == 'idf':\n",
        "        labels = []\n",
        "        for x in vec2.keys():\n",
        "            # idf_title_vectorizer.vocabulary_ it contains all the words in the corpus\n",
        "            # idf_title_features[doc_id, index_of_word_in_corpus] will give the idf value of word in given document (doc_id)\n",
        "            if x in  idf_title_vectorizer.vocabulary_:\n",
        "                labels.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[x]])\n",
        "            else:\n",
        "                labels.append(0)\n",
        "\n",
        "    plot_heatmap(keys, values, labels, url, text)\n",
        "\n",
        "\n",
        "# this function gets a list of wrods along with the frequency of each\n",
        "# word given \"text\"\n",
        "def text_to_vector(text):\n",
        "    word = re.compile(r'\\w+')\n",
        "    words = word.findall(text)\n",
        "    # words stores list of all words in given string, you can try 'words = text.split()' this will also gives same result\n",
        "    return Counter(words) # Counter counts the occurence of each word in list, it returns dict type object {word1:count}\n",
        "\n",
        "\n",
        "\n",
        "def get_result(doc_id, content_a, content_b, url, model):\n",
        "    text1 = content_a\n",
        "    text2 = content_b\n",
        "\n",
        "    # vector1 = dict{word11:#count, word12:#count, etc.}\n",
        "    vector1 = text_to_vector(text1)\n",
        "\n",
        "    # vector1 = dict{word21:#count, word22:#count, etc.}\n",
        "    vector2 = text_to_vector(text2)\n",
        "\n",
        "    plot_heatmap_image(doc_id, vector1, vector2, url, text2, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJzG6y3XN5X4"
      },
      "source": [
        "## [8.2] Bag of Words (BoW) on product titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTWUquNPN5X5"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "title_vectorizer = CountVectorizer()\n",
        "title_features   = title_vectorizer.fit_transform(data['title'])\n",
        "title_features.get_shape() # get number of rows and columns in feature matrix.\n",
        "# title_features.shape = #data_points * #words_in_corpus\n",
        "# CountVectorizer().fit_transform(corpus) returns\n",
        "# the a sparase matrix of dimensions #data_points * #words_in_corpus\n",
        "\n",
        "# What is a sparse vector?\n",
        "\n",
        "# title_features[doc_id, index_of_word_in_corpus] = number of times the word occured in that doc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHm5hRxnN5X9"
      },
      "outputs": [],
      "source": [
        "def bag_of_words_model(doc_id, num_results):\n",
        "    # doc_id: apparel's id in given corpus\n",
        "\n",
        "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
        "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
        "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
        "    pairwise_dist = pairwise_distances(title_features,title_features[doc_id])\n",
        "\n",
        "    # np.argsort will return indices of the smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "    for i in range(0,len(indices)):\n",
        "        # we will pass 1. doc_id, 2. title1, 3. title2, url, model\n",
        "        get_result(indices[i],data['title'].loc[df_indices[0]], data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], 'bag_of_words')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print ('Brand:', data['brand'].loc[df_indices[i]])\n",
        "        print ('Title:', data['title'].loc[df_indices[i]])\n",
        "        print ('Euclidean similarity with the query image :', pdists[i])\n",
        "        print('='*60)\n",
        "\n",
        "#call the bag-of-words model for a product to get similar products.\n",
        "bag_of_words_model(12566, 20) # change the index if you want to.\n",
        "# In the output heat map each value represents the count value\n",
        "# of the label word, the color represents the intersection\n",
        "# with inputs title.\n",
        "\n",
        "#try 12566\n",
        "#try 931"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LOG5lcnN5YB"
      },
      "source": [
        "## [8.5] TF-IDF based product similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZi19rI9N5YC"
      },
      "outputs": [],
      "source": [
        "tfidf_title_vectorizer = TfidfVectorizer(min_df = 0)\n",
        "tfidf_title_features = tfidf_title_vectorizer.fit_transform(data['title'])\n",
        "# tfidf_title_features.shape = #data_points * #words_in_corpus\n",
        "# CountVectorizer().fit_transform(courpus) returns the a sparase matrix of dimensions #data_points * #words_in_corpus\n",
        "# tfidf_title_features[doc_id, index_of_word_in_corpus] = tfidf values of the word in given doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qv_-c7-N5YG"
      },
      "outputs": [],
      "source": [
        "def tfidf_model(doc_id, num_results):\n",
        "    # doc_id: apparel's id in given corpus\n",
        "\n",
        "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
        "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
        "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
        "    pairwise_dist = pairwise_distances(tfidf_title_features,tfidf_title_features[doc_id])\n",
        "\n",
        "    # np.argsort will return indices of 9 smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the 9 smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "    for i in range(0,len(indices)):\n",
        "        # we will pass 1. doc_id, 2. title1, 3. title2, url, model\n",
        "        get_result(indices[i], data['title'].loc[df_indices[0]], data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], 'tfidf')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print('BRAND :',data['brand'].loc[df_indices[i]])\n",
        "        print ('Eucliden distance from the given image :', pdists[i])\n",
        "        print('='*125)\n",
        "tfidf_model(12566, 20)\n",
        "# in the output heat map each value represents the tfidf values of the label word, the color represents the intersection with inputs title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Q45PWUN5YK"
      },
      "source": [
        "## [8.5] IDF based product similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoMyiPpbN5YO"
      },
      "outputs": [],
      "source": [
        "idf_title_vectorizer = CountVectorizer()\n",
        "idf_title_features = idf_title_vectorizer.fit_transform(data['title'])\n",
        "\n",
        "# idf_title_features.shape = #data_points * #words_in_corpus\n",
        "# CountVectorizer().fit_transform(courpus) returns the a sparase matrix of dimensions #data_points * #words_in_corpus\n",
        "# idf_title_features[doc_id, index_of_word_in_corpus] = number of times the word occured in that doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9nBYwOmN5YS"
      },
      "outputs": [],
      "source": [
        "def n_containing(word):\n",
        "    # return the number of documents which had the given word\n",
        "    return sum(1 for blob in data['title'] if word in blob.split())\n",
        "\n",
        "def idf(word):\n",
        "    # idf = log(#number of docs / #number of docs which had the given word)\n",
        "    return math.log(data.shape[0] / (n_containing(word)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEH_7rHQN5YV"
      },
      "outputs": [],
      "source": [
        "# we need to convert the values into float\n",
        "idf_title_features  = idf_title_features.astype(np.float)\n",
        "\n",
        "for i in idf_title_vectorizer.vocabulary_.keys():\n",
        "    # for every word in whole corpus we will find its idf value\n",
        "    idf_val = idf(i)\n",
        "\n",
        "    # to calculate idf_title_features we need to replace the count values with the idf values of the word\n",
        "    # idf_title_features[:, idf_title_vectorizer.vocabulary_[i]].nonzero()[0] will return all documents in which the word i present\n",
        "    for j in idf_title_features[:, idf_title_vectorizer.vocabulary_[i]].nonzero()[0]:\n",
        "\n",
        "        # we replace the count values of word i in document j with  idf_value of word i\n",
        "        # idf_title_features[doc_id, index_of_word_in_courpus] = idf value of word\n",
        "        idf_title_features[j,idf_title_vectorizer.vocabulary_[i]] = idf_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fxRj3XwN5YY",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def idf_model(doc_id, num_results):\n",
        "    # doc_id: apparel's id in given corpus\n",
        "\n",
        "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
        "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
        "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
        "    pairwise_dist = pairwise_distances(idf_title_features,idf_title_features[doc_id])\n",
        "\n",
        "    # np.argsort will return indices of 9 smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the 9 smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "    for i in range(0,len(indices)):\n",
        "        get_result(indices[i],data['title'].loc[df_indices[0]], data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], 'idf')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print('Brand :',data['brand'].loc[df_indices[i]])\n",
        "        print ('euclidean distance from the given image :', pdists[i])\n",
        "        print('='*125)\n",
        "\n",
        "\n",
        "\n",
        "idf_model(12566,20)\n",
        "# in the output heat map each value represents the idf values of the label word, the color represents the intersection with inputs title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ugwIoD8N5Yb"
      },
      "source": [
        "# [9] Text Semantics based product similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h14bdZYN5Yc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# credits: https://www.kaggle.com/c/word2vec-nlp-tutorial#part-2-word-vectors\n",
        "# Custom Word2Vec using your own text data.\n",
        "# Do NOT RUN this code.\n",
        "# It is meant as a reference to build your own Word2Vec when you have\n",
        "# lots of data.\n",
        "\n",
        "'''\n",
        "# Set values for various parameters\n",
        "num_features = 300    # Word vector dimensionality\n",
        "min_word_count = 1    # Minimum word count\n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size\n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "# Initialize and train the model (this will take some time)\n",
        "from gensim.models import word2vec\n",
        "print (\"Training model...\")\n",
        "model = word2vec.Word2Vec(sen_corpus, workers=num_workers, \\\n",
        "            size=num_features, min_count = min_word_count, \\\n",
        "            window = context)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv-Dva8xN5Yg"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "\n",
        "# in this project we are using a pretrained model by google\n",
        "# its 3.3G file, once you load this into your memory\n",
        "# it occupies ~9Gb, so please do this step only if you have >12G of ram\n",
        "# we will provide a pickle file wich contains a dict ,\n",
        "# and it contains all our courpus words as keys and  model[word] as values\n",
        "# To use this code-snippet, download \"GoogleNews-vectors-negative300.bin\"\n",
        "# from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
        "# it's 1.9GB in size.\n",
        "\n",
        "'''\n",
        "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "'''\n",
        "\n",
        "#if you do NOT have RAM >= 12GB, use the code below.\n",
        "with open('word2vec_model', 'rb') as handle:\n",
        "    model = pickle.load(handle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmSvdqZCN5Yj"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def get_word_vec(sentence, doc_id, m_name):\n",
        "    # sentence : title of the apparel\n",
        "    # doc_id: document id in our corpus\n",
        "    # m_name: model information it will take two values\n",
        "        # if  m_name == 'avg', we will append the model[i], w2v representation of word i\n",
        "        # if m_name == 'weighted', we will multiply each w2v[word] with the idf(word)\n",
        "    vec = []\n",
        "    for i in sentence.split():\n",
        "        if i in vocab:\n",
        "            if m_name == 'weighted' and i in  idf_title_vectorizer.vocabulary_:\n",
        "                vec.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[i]] * model[i])\n",
        "            elif m_name == 'avg':\n",
        "                vec.append(model[i])\n",
        "        else:\n",
        "            # if the word in our courpus is not there in the google word2vec corpus, we are just ignoring it\n",
        "            vec.append(np.zeros(shape=(300,)))\n",
        "    # we will return a numpy array of shape (#number of words in title * 300 ) 300 = len(w2v_model[word])\n",
        "    # each row represents the word2vec representation of each word (weighted/avg) in given sentance\n",
        "    return  np.array(vec)\n",
        "\n",
        "def get_distance(vec1, vec2):\n",
        "    # vec1 = np.array(#number_of_words_title1 * 300), each row is a vector of length 300 corresponds to each word in give title\n",
        "    # vec2 = np.array(#number_of_words_title2 * 300), each row is a vector of length 300 corresponds to each word in give title\n",
        "\n",
        "    final_dist = []\n",
        "    # for each vector in vec1 we caluclate the distance(euclidean) to all vectors in vec2\n",
        "    for i in vec1:\n",
        "        dist = []\n",
        "        for j in vec2:\n",
        "            # np.linalg.norm(i-j) will result the euclidean distance between vectors i, j\n",
        "            dist.append(np.linalg.norm(i-j))\n",
        "        final_dist.append(np.array(dist))\n",
        "    # final_dist = np.array(#number of words in title1 * #number of words in title2)\n",
        "    # final_dist[i,j] = euclidean distance between vectors i, j\n",
        "    return np.array(final_dist)\n",
        "\n",
        "\n",
        "def heat_map_w2v(sentence1, sentence2, url, doc_id1, doc_id2, model):\n",
        "    # sentance1 : title1, input apparel\n",
        "    # sentance2 : title2, recommended apparel\n",
        "    # url: apparel image url\n",
        "    # doc_id1: document id of input apparel\n",
        "    # doc_id2: document id of recommended apparel\n",
        "    # model: it can have two values, 1. avg 2. weighted\n",
        "\n",
        "    #s1_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
        "    s1_vec = get_word_vec(sentence1, doc_id1, model)\n",
        "    #s2_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
        "    s2_vec = get_word_vec(sentence2, doc_id2, model)\n",
        "\n",
        "    # s1_s2_dist = np.array(#number of words in title1 * #number of words in title2)\n",
        "    # s1_s2_dist[i,j] = euclidean distance between words i, j\n",
        "    s1_s2_dist = get_distance(s1_vec, s2_vec)\n",
        "\n",
        "\n",
        "\n",
        "    # devide whole figure into 2 parts 1st part displays heatmap 2nd part displays image of apparel\n",
        "    gs = gridspec.GridSpec(2, 2, width_ratios=[4,1],height_ratios=[2,1])\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "\n",
        "    ax = plt.subplot(gs[0])\n",
        "    # ploting the heap map based on the pairwise distances\n",
        "    ax = sns.heatmap(np.round(s1_s2_dist,4), annot=True)\n",
        "    # set the x axis labels as recommended apparels title\n",
        "    ax.set_xticklabels(sentence2.split())\n",
        "    # set the y axis labels as input apparels title\n",
        "    ax.set_yticklabels(sentence1.split())\n",
        "    # set title as recommended apparels title\n",
        "    ax.set_title(sentence2)\n",
        "\n",
        "    ax = plt.subplot(gs[1])\n",
        "    # we remove all grids and axis labels for image\n",
        "    ax.grid(False)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    display_img(url, ax, fig)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_3dfdlUN5Yn"
      },
      "outputs": [],
      "source": [
        "# vocab = stores all the words that are there in google w2v model\n",
        "# vocab = model.wv.vocab.keys() # if you are using Google word2Vec\n",
        "\n",
        "vocab = model.keys()\n",
        "# this function will add the vectors of each word and returns the avg vector of given sentance\n",
        "def build_avg_vec(sentence, num_features, doc_id, m_name):\n",
        "    # sentace: its title of the apparel\n",
        "    # num_features: the lenght of word2vec vector, its values = 300\n",
        "    # m_name: model information it will take two values\n",
        "        # if  m_name == 'avg', we will append the model[i], w2v representation of word i\n",
        "        # if m_name == 'weighted', we will multiply each w2v[word] with the idf(word)\n",
        "\n",
        "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
        "    # we will intialize a vector of size 300 with all zeros\n",
        "    # we add each word2vec(wordi) to this fetureVec\n",
        "    nwords = 0\n",
        "\n",
        "    for word in sentence.split():\n",
        "        nwords += 1\n",
        "        if word in vocab:\n",
        "            if m_name == 'weighted' and word in  idf_title_vectorizer.vocabulary_:\n",
        "                featureVec = np.add(featureVec, idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[word]] * model[word])\n",
        "            elif m_name == 'avg':\n",
        "                featureVec = np.add(featureVec, model[word])\n",
        "    if(nwords>0):\n",
        "        featureVec = np.divide(featureVec, nwords)\n",
        "    # returns the avg vector of given sentance, its of shape (1, 300)\n",
        "    return featureVec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h93loi_9N5Yt"
      },
      "source": [
        "### [9.2] Average Word2Vec product similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avJ3bOldN5Yu"
      },
      "outputs": [],
      "source": [
        "doc_id = 0\n",
        "w2v_title = []\n",
        "# for every title we build a avg vector representation\n",
        "for i in data['title']:\n",
        "    w2v_title.append(build_avg_vec(i, 300, doc_id,'avg'))\n",
        "    doc_id += 1\n",
        "\n",
        "# w2v_title = np.array(# number of doc in courpus * 300), each row corresponds to a doc\n",
        "w2v_title = np.array(w2v_title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04f-PtPdN5Yx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def avg_w2v_model(doc_id, num_results):\n",
        "    # doc_id: apparel's id in given corpus\n",
        "\n",
        "    # dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))\n",
        "    pairwise_dist = pairwise_distances(w2v_title, w2v_title[doc_id].reshape(1,-1))\n",
        "\n",
        "    # np.argsort will return indices of 9 smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the 9 smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "    for i in range(0, len(indices)):\n",
        "        heat_map_w2v(data['title'].loc[df_indices[0]],data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i], 'avg')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print('BRAND :',data['brand'].loc[df_indices[i]])\n",
        "        print ('euclidean distance from given input image :', pdists[i])\n",
        "        print('='*125)\n",
        "\n",
        "\n",
        "avg_w2v_model(12566, 20)\n",
        "# in the give heat map, each cell contains the euclidean distance between words i, j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HUSFiQYN5Y1"
      },
      "source": [
        "### [9.4]  IDF weighted Word2Vec for product similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxWYF3icN5Y2"
      },
      "outputs": [],
      "source": [
        "doc_id = 0\n",
        "w2v_title_weight = []\n",
        "# for every title we build a weighted vector representation\n",
        "for i in data['title']:\n",
        "    w2v_title_weight.append(build_avg_vec(i, 300, doc_id,'weighted'))\n",
        "    doc_id += 1\n",
        "# w2v_title = np.array(# number of doc in courpus * 300), each row corresponds to a doc\n",
        "w2v_title_weight = np.array(w2v_title_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS4c0n8VN5Y6"
      },
      "outputs": [],
      "source": [
        "def weighted_w2v_model(doc_id, num_results):\n",
        "    # doc_id: apparel's id in given corpus\n",
        "\n",
        "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
        "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
        "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
        "    pairwise_dist = pairwise_distances(w2v_title_weight, w2v_title_weight[doc_id].reshape(1,-1))\n",
        "\n",
        "    # np.argsort will return indices of 9 smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the 9 smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "    for i in range(0, len(indices)):\n",
        "        heat_map_w2v(data['title'].loc[df_indices[0]],data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i], 'weighted')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print('Brand :',data['brand'].loc[df_indices[i]])\n",
        "        print('euclidean distance from input :', pdists[i])\n",
        "        print('='*125)\n",
        "\n",
        "weighted_w2v_model(12566, 20)\n",
        "#931\n",
        "#12566\n",
        "# in the give heat map, each cell contains the euclidean distance between words i, j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5CQeoxZN5Y-"
      },
      "source": [
        "### [9.6] Weighted similarity using brand and color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2NbzPgEN5Y_"
      },
      "outputs": [],
      "source": [
        "# some of the brand values are empty.\n",
        "# Need to replace Null with string \"NULL\"\n",
        "data['brand'].fillna(value=\"Not given\", inplace=True )\n",
        "\n",
        "# replace spaces with hypen\n",
        "brands = [x.replace(\" \", \"-\") for x in data['brand'].values]\n",
        "types = [x.replace(\" \", \"-\") for x in data['product_type_name'].values]\n",
        "colors = [x.replace(\" \", \"-\") for x in data['color'].values]\n",
        "\n",
        "brand_vectorizer = CountVectorizer()\n",
        "brand_features = brand_vectorizer.fit_transform(brands)\n",
        "\n",
        "type_vectorizer = CountVectorizer()\n",
        "type_features = type_vectorizer.fit_transform(types)\n",
        "\n",
        "color_vectorizer = CountVectorizer()\n",
        "color_features = color_vectorizer.fit_transform(colors)\n",
        "\n",
        "extra_features = hstack((brand_features, type_features, color_features)).tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxxuI2isN5ZD"
      },
      "outputs": [],
      "source": [
        "def heat_map_w2v_brand(sentance1, sentance2, url, doc_id1, doc_id2, df_id1, df_id2, model):\n",
        "\n",
        "    # sentance1 : title1, input apparel\n",
        "    # sentance2 : title2, recommended apparel\n",
        "    # url: apparel image url\n",
        "    # doc_id1: document id of input apparel\n",
        "    # doc_id2: document id of recommended apparel\n",
        "    # df_id1: index of document1 in the data frame\n",
        "    # df_id2: index of document2 in the data frame\n",
        "    # model: it can have two values, 1. avg 2. weighted\n",
        "\n",
        "    #s1_vec = np.array(#number_of_words_title1 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
        "    s1_vec = get_word_vec(sentance1, doc_id1, model)\n",
        "    #s2_vec = np.array(#number_of_words_title2 * 300), each row is a vector(weighted/avg) of length 300 corresponds to each word in give title\n",
        "    s2_vec = get_word_vec(sentance2, doc_id2, model)\n",
        "\n",
        "    # s1_s2_dist = np.array(#number of words in title1 * #number of words in title2)\n",
        "    # s1_s2_dist[i,j] = euclidean distance between words i, j\n",
        "    s1_s2_dist = get_distance(s1_vec, s2_vec)\n",
        "\n",
        "    data_matrix = [['Asin','Brand', 'Color', 'Product type'],\n",
        "               [data['asin'].loc[df_id1],brands[doc_id1], colors[doc_id1], types[doc_id1]], # input apparel's features\n",
        "               [data['asin'].loc[df_id2],brands[doc_id2], colors[doc_id2], types[doc_id2]]] # recommonded apparel's features\n",
        "\n",
        "    colorscale = [[0, '#1d004d'],[.5, '#f2e5ff'],[1, '#f2e5d1']] # to color the headings of each column\n",
        "\n",
        "    # we create a table with the data_matrix\n",
        "    table = ff.create_table(data_matrix, index=True, colorscale=colorscale)\n",
        "    # plot it with plotly\n",
        "    plotly.offline.iplot(table, filename='simple_table')\n",
        "\n",
        "    # devide whole figure space into 25 * 1:10 grids\n",
        "    gs = gridspec.GridSpec(25, 15)\n",
        "    fig = plt.figure(figsize=(25,5))\n",
        "\n",
        "    # in first 25*10 grids we plot heatmap\n",
        "    ax1 = plt.subplot(gs[:, :-5])\n",
        "    # ploting the heap map based on the pairwise distances\n",
        "    ax1 = sns.heatmap(np.round(s1_s2_dist,6), annot=True)\n",
        "    # set the x axis labels as recommended apparels title\n",
        "    ax1.set_xticklabels(sentance2.split())\n",
        "    # set the y axis labels as input apparels title\n",
        "    ax1.set_yticklabels(sentance1.split())\n",
        "    # set title as recommended apparels title\n",
        "    ax1.set_title(sentance2)\n",
        "\n",
        "    # in last 25 * 10:15 grids we display image\n",
        "    ax2 = plt.subplot(gs[:, 10:16])\n",
        "    # we dont display grid lins and axis labels to images\n",
        "    ax2.grid(False)\n",
        "    ax2.set_xticks([])\n",
        "    ax2.set_yticks([])\n",
        "\n",
        "    # pass the url it display it\n",
        "    display_img(url, ax2, fig)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu19_u6YN5ZF"
      },
      "outputs": [],
      "source": [
        "def idf_w2v_brand(doc_id, w1, w2, num_results):\n",
        "    # doc_id: apparel's id in given corpus\n",
        "    # w1: weight for  w2v features\n",
        "    # w2: weight for brand and color features\n",
        "\n",
        "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
        "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
        "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
        "    idf_w2v_dist  = pairwise_distances(w2v_title_weight, w2v_title_weight[doc_id].reshape(1,-1))\n",
        "    ex_feat_dist = pairwise_distances(extra_features, extra_features[doc_id])\n",
        "    pairwise_dist   = (w1 * idf_w2v_dist +  w2 * ex_feat_dist)/float(w1 + w2)\n",
        "\n",
        "    # np.argsort will return indices of 9 smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the 9 smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "\n",
        "    for i in range(0, len(indices)):\n",
        "        heat_map_w2v_brand(data['title'].loc[df_indices[0]],data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i],df_indices[0], df_indices[i], 'weighted')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print('Brand :',data['brand'].loc[df_indices[i]])\n",
        "        print('euclidean distance from input :', pdists[i])\n",
        "        print('='*125)\n",
        "\n",
        "idf_w2v_brand(12566, 5, 5, 20)\n",
        "# in the give heat map, each cell contains the euclidean distance between words i, j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jy4uAcQN5ZP"
      },
      "outputs": [],
      "source": [
        "# brand and color weight =50\n",
        "# title vector weight = 5\n",
        "\n",
        "idf_w2v_brand(12566, 5, 50, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "5wVemGlRN5ZT",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "# [10.2] Keras and Tensorflow to extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM8gwYlXN5ZV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RxA43ohN5ZZ"
      },
      "outputs": [],
      "source": [
        "# https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069\n",
        "# Code reference: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "\n",
        "\n",
        "\n",
        "# This code takes 40 minutes to run on a modern GPU (graphics card)\n",
        "# like Nvidia  1050.\n",
        "# GPU (NVidia 1050): 0.175 seconds per image\n",
        "\n",
        "# This codse takes 160 minutes to run on a high end i7 CPU\n",
        "# CPU (i7): 0.615 seconds per image.\n",
        "\n",
        "#Do NOT run this code unless you want to wait a few hours for it to generate output\n",
        "\n",
        "# each image is converted into 25088 length dense-vector\n",
        "\n",
        "\n",
        "'''\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
        "train_data_dir = 'images2/'\n",
        "nb_train_samples = 16042\n",
        "epochs = 50\n",
        "batch_size = 1\n",
        "\n",
        "\n",
        "def save_bottlebeck_features():\n",
        "\n",
        "    #Function to compute VGG-16 CNN for image feature extraction.\n",
        "\n",
        "    asins = []\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "\n",
        "    for i in generator.filenames:\n",
        "        asins.append(i[2:-5])\n",
        "\n",
        "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
        "    bottleneck_features_train = bottleneck_features_train.reshape((16042,25088))\n",
        "\n",
        "    np.save(open('16k_data_cnn_features.npy', 'wb'), bottleneck_features_train)\n",
        "    np.save(open('16k_data_cnn_feature_asins.npy', 'wb'), np.array(asins))\n",
        "\n",
        "\n",
        "save_bottlebeck_features()\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUfr1LITN5Zd"
      },
      "source": [
        "# [10.3] Visual features based product similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSTnr4PN5Ze"
      },
      "outputs": [],
      "source": [
        "#load the features and corresponding ASINS info.\n",
        "bottleneck_features_train = np.load('16k_data_cnn_features.npy')\n",
        "asins = np.load('16k_data_cnn_feature_asins.npy')\n",
        "asins = list(asins)\n",
        "\n",
        "# load the original 16K dataset\n",
        "data = pd.read_pickle('pickels/16k_apperal_data_preprocessed')\n",
        "df_asins = list(data['asin'])\n",
        "\n",
        "\n",
        "from IPython.display import display, Image, SVG, Math, YouTubeVideo\n",
        "\n",
        "\n",
        "#get similar products using CNN features (VGG-16)\n",
        "def get_similar_products_cnn(doc_id, num_results):\n",
        "    doc_id = asins.index(df_asins[doc_id])\n",
        "    pairwise_dist = pairwise_distances(bottleneck_features_train, bottleneck_features_train[doc_id].reshape(1,-1))\n",
        "\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    for i in range(len(indices)):\n",
        "        rows = data[['medium_image_url','title']].loc[data['asin']==asins[indices[i]]]\n",
        "        for indx, row in rows.iterrows():\n",
        "            display(Image(url=row['medium_image_url'], embed=True))\n",
        "            print('Product Title: ', row['title'])\n",
        "            print('Euclidean Distance from input image:', pdists[i])\n",
        "            print('Amazon Url: www.amzon.com/dp/'+ asins[indices[i]])\n",
        "\n",
        "get_similar_products_cnn(12566, 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9pPK6-TN5Zh"
      },
      "outputs": [],
      "source": [
        "## Assignment\n",
        "========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOGVMY9UShZB"
      },
      "outputs": [],
      "source": [
        "def weighted_similarity(doc_id,num_results,text_vector,wt = 1,wb = 1,wc = 1,wi = 1):\n",
        "    \"\"\"\n",
        "    This function consider 4 vectors.\n",
        "    1. Text (by default tfidf w2v in considered.)\n",
        "    2. Brand\n",
        "    3. Color\n",
        "    4. Feature Extracted image vector\n",
        "\n",
        "    Weighted similarity vector is calculated based on weights provided.\n",
        "    By default all weights are 1.\n",
        "\n",
        "    Please pass the string which vectorizer to used.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
        "    # getting all the similarity distances for the given doc_id into into corresponding lists.\n",
        "\n",
        "    if text_vector == \"bow\":\n",
        "        # bow\n",
        "        text_dist = pairwise_distances(title_features,title_features[doc_id])\n",
        "    elif text_vector ==\"tfidf\":\n",
        "        # tfidf\n",
        "        text_dist = pairwise_distances(tfidf_title_features,tfidf_title_features[doc_id])\n",
        "    elif text_vector == \"avg_w2v\":\n",
        "        # avg_w2v\n",
        "        text_dist = pairwise_distances(w2v_title, w2v_title[doc_id].reshape(1,-1))\n",
        "    elif text_vector == \"idf_w2v\":\n",
        "        # tfidf_avg_w2v\n",
        "        text_dist  = pairwise_distances(w2v_title_weight, w2v_title_weight[doc_id].reshape(1,-1))\n",
        "\n",
        "    brand_dist = pairwise_distances(brand_features, brand_features[doc_id])\n",
        "    color_dist = pairwise_distances(color_features, color_features[doc_id])\n",
        "    image_dist = pairwise_distances(bottleneck_features_train, bottleneck_features_train[doc_id].reshape(1,-1))\n",
        "\n",
        "    # calculating weighted vector.\n",
        "    pairwise_dist   = ((wt * text_dist) +(wb * brand_dist) +(wc * color_dist) + (wi * image_dist))/float(wt + wb + wc + wi)\n",
        "\n",
        "    # np.argsort will return indices of 9 smallest distances\n",
        "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
        "    #pdists will store the 9 smallest distances\n",
        "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
        "\n",
        "    #data frame indices of the 9 smallest distace's\n",
        "    df_indices = list(data.index[indices])\n",
        "\n",
        "\n",
        "    for i in range(0, len(indices)):\n",
        "        heat_map_w2v_brand(data['title'].loc[df_indices[0]],data['title'].loc[df_indices[i]], data['medium_image_url'].loc[df_indices[i]], indices[0], indices[i],df_indices[0], df_indices[i], 'weighted')\n",
        "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
        "        print('Brand :',data['brand'].loc[df_indices[i]])\n",
        "        print('Color :',data['color'].loc[df_indices[i]])\n",
        "        print('euclidean distance from input :', pdists[i])\n",
        "        print('='*125)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-AEanV2ShZC"
      },
      "source": [
        "#### 1. Consider [text bow] + [brand] + [color] + [image]\n",
        "======================================================\n",
        "- Weights are assigned for above\n",
        "- By default all weights are 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCMoYkIAShZD"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_D8Y_gjShZE"
      },
      "source": [
        "Weight to image_vector = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDOyHgjiShZE"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"tfidf\",wt=0,wb=1,wc=3,wi=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FhJMsu9ShZF"
      },
      "source": [
        "Weight to text_vector = \"bow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbVHXfX6ShZF"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"bow\",wt=5,wb=2,wc=2,wi=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvZLV1N-ShZG"
      },
      "source": [
        "Weight to text_vector = \"avg_w2v\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOrMuwePShZG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"avg_w2v\",wt=5,wb=2,wc=2,wi=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBmsP4mnShZH"
      },
      "source": [
        "#### 2. Consider  [text tfidf ] + [brand] + [color] + [image]\n",
        "======================================================\n",
        "- Weights are assigned for above\n",
        "- By default all weights are 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEK6-rB5ShZI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"tfidf\",wt=5,wb=5,wc=5,wi=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSI27mN4ShZI"
      },
      "source": [
        "More weight to text,brand and color as compare to image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KrnwU-ZShZJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"tfidf\",wt=10,wb=10,wc=10,wi=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiczGfnCShZJ"
      },
      "source": [
        "Brand weight to zero. More to Text,color and  image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6Y6yaMyShZK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"tfidf\",wt=0.10,wb=0,wc=0.10,wi=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLPGdE1tShZK"
      },
      "source": [
        "#### 3. Consider [text avg_w2v] + [brand] + [color] + [image]\n",
        "======================================================\n",
        "- Weights are assigned for above\n",
        "- By default all weights are 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbDb3LlxShZL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"avg_w2v\",wt=10,wb=10,wc=10,wi=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk_v6vEbShZL"
      },
      "source": [
        "- More weight to image and text.\n",
        "- Brand and color to zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K1SBcPRShZM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"avg_w2v\",wt=10,wb=10,wc=10,wi=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqBFoYtLShZO"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"avg_w2v\",wt=10,wb=10,wc=0,wi=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtZcLRuXShZP"
      },
      "source": [
        "#### 4. Consider [text tfidf_w2v] + [brand] + [color] + [image]\n",
        "======================================================\n",
        "- Weights are assigned for above\n",
        "- By default all weights are 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDYVYWqXShZP"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"idf_w2v\",wt=10,wb=10,wc=0,wi=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCvA18KOShZQ"
      },
      "source": [
        "Equal weights to text,brand,color and lesser weight to image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxr9JhKyShZQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"idf_w2v\",wt=10,wb=10,wc=10,wi=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7abDwRVdShZR"
      },
      "source": [
        "- Zero weight to brand.\n",
        "- Lesser to image.\n",
        "- More weight to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l13xHtteShZR"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"idf_w2v\",wt=15,wb=0,wc=10,wi=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDQJqKHPShZS"
      },
      "outputs": [],
      "source": [
        "weighted_similarity(12566,10,text_vector=\"idf_w2v\",wt=15,wb=10,wc=15,wi=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FTYLi3IShZS"
      },
      "source": [
        "### Observations:\n",
        "=====================\n",
        "\n",
        "1. Results were best when considered only text,brand and color.\n",
        "2. Recommended products were completly different when considered combination of all the vectors.\n",
        "3. Wide range of different apparels were recommended when **feature extracted image vector** considered.\n",
        "4. When feature extracted image considered\n",
        "    - Increase in similarity distance found\n",
        "    - Recommended products were completly different and non relevant.\n",
        "    - Performance deterioted when higher weights were assignrd.\n",
        "\n",
        "5. The reason behind it could be, that **apparel image dataset** is far different than **imagenet dataset.**.\n",
        "6. Feature extracted image vector can be improove the product recommendation if **VGG16 fine tuned on apparel image dataset.**\n",
        "7. Among various text encoding, best result was found in case of tfidf_avg_w2v.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzkc6OpRShZT"
      },
      "source": [
        "### CaseStudy Flow:\n",
        "========================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNALbjiXShZT"
      },
      "source": [
        "- The objective of case study is to recommend similar apparel products(women's top)\n",
        "- The data was obtained from **Amazon Product advertising API.**\n",
        "- Total **183k data point was obtained with 19 features** such as asin,author,availability,availability_type,  brand, color  formatted_price etc.,\n",
        "- We are considering only 9 features.\n",
        "    1. asin  ( Amazon standard identification number)\n",
        "    2. brand ( brand to which the product belongs to )\n",
        "    3. color ( Color information of apparel, it can contain many colors as   a value ex: red and black stripes )\n",
        "    4. product_type_name (type of the apperal, ex: SHIRT/TSHIRT )\n",
        "    5. medium_image_url  ( url of the image )\n",
        "    6. title (title of the product.)\n",
        "    7. formatted_price (price of product)\n",
        "- Data pre-processing and cleaning was done. Null values for brand,color  was replaced with hypen.\n",
        "- EDA was done on title of product to remoove similar/analogus titles.\n",
        "- Final dataframe contains 16k data points with 9 features.\n",
        "- Categorical features were one hot encoded with the help of countvectorizer.\n",
        "- Text feature was encoded using bow,tfidf,avg_w2v and tfidf_avg_w2v.\n",
        "- Similar products based on text was shown to check weather it is working correctly or not.\n",
        "- **VGG16** was used to extract **feature from product images**.\n",
        "- Combination of weighted vector [text + (brand + color) + image ] is used to get similar products.\n",
        "- Observation are noted down whenever necessary.\n",
        "- Results of case study is summarized at the end.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MD7dXGzShZU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}